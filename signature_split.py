#!/usr/bin/python
# -+- coding: utf-8 -+-
import re,os
import sys,io
from jieba_cut import seg_sentence

fout1=open("wordclustering\\sourcedata\\source_file","w",encoding="UTF-8")
fout2=open("No_NickName_Signature.csv","w")
f=open("memberList.csv",encoding="UTF-8")
f.readline()
lines=f.readlines()
for No, line in enumerate(lines):
	line=line.encode("gbk", "ignore").decode("gbk")
	# å°†Unicodeç¼–ç è½¬æ¢æˆgbkç¼–ç ï¼Œåœ¨è½¬æ¢çš„è¿‡ç¨‹ä¸­é€šè¿‡â€œignoreâ€å¿½ç•¥æ‰gbkä¸èƒ½è¯†åˆ«çš„å­—ç¬¦ï¼ˆğŸ˜’ï¼‰ï¼Œ
	# ç„¶åå†æŠŠgbkè½¬æ¢æˆUnicodeç¼–ç ,æ¯•ç«Ÿç‰ºç‰²éƒ¨åˆ†å­—ç¬¦ä¸²ã€‚
	line=line.strip("\r\n")
	NickName,Sex,Province,City,Signature=line.split(',',4)
	Signature=re.sub(r'<span.*/span>','',Signature)
	keyword_list=seg_sentence(Signature)
	write_line1=','.join([str(No),keyword_list])
	fout1.write(write_line1+'\n')
	write_line2=','.join([str(No),NickName,Signature])
	fout2.write(write_line2+'\n')
